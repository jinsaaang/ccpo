{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f594e782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from data.data_loader import TimeSeriesDataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from layers.multi_cp import SPCI_and_EnbPI\n",
    "from models.lstm import LSTMModel\n",
    "\n",
    "print(\"Data loader imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9b3360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>XOM</th>\n",
       "      <th>JPM</th>\n",
       "      <th>PG</th>\n",
       "      <th>CVX</th>\n",
       "      <th>MRK</th>\n",
       "      <th>KO</th>\n",
       "      <th>PEP</th>\n",
       "      <th>...</th>\n",
       "      <th>KR</th>\n",
       "      <th>COP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>NOC</th>\n",
       "      <th>KMB</th>\n",
       "      <th>MO</th>\n",
       "      <th>ADM</th>\n",
       "      <th>GIS</th>\n",
       "      <th>PPG</th>\n",
       "      <th>DE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>18.454880</td>\n",
       "      <td>0.949987</td>\n",
       "      <td>34.751911</td>\n",
       "      <td>25.093662</td>\n",
       "      <td>22.368937</td>\n",
       "      <td>31.104504</td>\n",
       "      <td>23.147207</td>\n",
       "      <td>14.135262</td>\n",
       "      <td>11.093916</td>\n",
       "      <td>28.976854</td>\n",
       "      <td>...</td>\n",
       "      <td>6.069591</td>\n",
       "      <td>16.229395</td>\n",
       "      <td>44.609112</td>\n",
       "      <td>31.197931</td>\n",
       "      <td>30.214354</td>\n",
       "      <td>4.115128</td>\n",
       "      <td>13.337941</td>\n",
       "      <td>12.691508</td>\n",
       "      <td>21.149090</td>\n",
       "      <td>24.427019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>18.523895</td>\n",
       "      <td>0.959743</td>\n",
       "      <td>34.641403</td>\n",
       "      <td>24.923332</td>\n",
       "      <td>22.138399</td>\n",
       "      <td>30.715654</td>\n",
       "      <td>22.988049</td>\n",
       "      <td>14.076481</td>\n",
       "      <td>10.939011</td>\n",
       "      <td>28.770435</td>\n",
       "      <td>...</td>\n",
       "      <td>5.906789</td>\n",
       "      <td>16.123270</td>\n",
       "      <td>44.042339</td>\n",
       "      <td>30.529194</td>\n",
       "      <td>30.228394</td>\n",
       "      <td>4.143637</td>\n",
       "      <td>13.192176</td>\n",
       "      <td>12.652571</td>\n",
       "      <td>20.671089</td>\n",
       "      <td>23.844303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>18.482491</td>\n",
       "      <td>0.968149</td>\n",
       "      <td>34.619312</td>\n",
       "      <td>24.793068</td>\n",
       "      <td>22.184502</td>\n",
       "      <td>31.036873</td>\n",
       "      <td>23.138121</td>\n",
       "      <td>14.171439</td>\n",
       "      <td>10.888270</td>\n",
       "      <td>28.803917</td>\n",
       "      <td>...</td>\n",
       "      <td>5.857239</td>\n",
       "      <td>16.242908</td>\n",
       "      <td>43.953110</td>\n",
       "      <td>30.994419</td>\n",
       "      <td>29.708813</td>\n",
       "      <td>4.136169</td>\n",
       "      <td>12.967444</td>\n",
       "      <td>12.912111</td>\n",
       "      <td>20.378616</td>\n",
       "      <td>23.613228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>18.461790</td>\n",
       "      <td>0.968900</td>\n",
       "      <td>34.718746</td>\n",
       "      <td>25.108692</td>\n",
       "      <td>22.311295</td>\n",
       "      <td>31.189054</td>\n",
       "      <td>23.524668</td>\n",
       "      <td>14.270920</td>\n",
       "      <td>10.979074</td>\n",
       "      <td>29.010326</td>\n",
       "      <td>...</td>\n",
       "      <td>5.811234</td>\n",
       "      <td>16.478315</td>\n",
       "      <td>43.905884</td>\n",
       "      <td>30.913008</td>\n",
       "      <td>30.190958</td>\n",
       "      <td>4.106984</td>\n",
       "      <td>13.234690</td>\n",
       "      <td>13.006134</td>\n",
       "      <td>20.667944</td>\n",
       "      <td>23.941425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>18.406567</td>\n",
       "      <td>1.039446</td>\n",
       "      <td>34.591671</td>\n",
       "      <td>24.943365</td>\n",
       "      <td>22.132635</td>\n",
       "      <td>31.515942</td>\n",
       "      <td>23.260893</td>\n",
       "      <td>14.076481</td>\n",
       "      <td>10.992427</td>\n",
       "      <td>29.261377</td>\n",
       "      <td>...</td>\n",
       "      <td>5.885553</td>\n",
       "      <td>16.374115</td>\n",
       "      <td>43.821911</td>\n",
       "      <td>30.849022</td>\n",
       "      <td>30.022442</td>\n",
       "      <td>4.167390</td>\n",
       "      <td>13.265059</td>\n",
       "      <td>13.303864</td>\n",
       "      <td>20.768570</td>\n",
       "      <td>23.609882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23</th>\n",
       "      <td>432.871429</td>\n",
       "      <td>254.367020</td>\n",
       "      <td>141.850220</td>\n",
       "      <td>103.433617</td>\n",
       "      <td>233.448151</td>\n",
       "      <td>164.928162</td>\n",
       "      <td>138.162003</td>\n",
       "      <td>96.588165</td>\n",
       "      <td>61.017918</td>\n",
       "      <td>146.899445</td>\n",
       "      <td>...</td>\n",
       "      <td>60.064949</td>\n",
       "      <td>94.021751</td>\n",
       "      <td>119.708084</td>\n",
       "      <td>461.087036</td>\n",
       "      <td>127.804871</td>\n",
       "      <td>49.940445</td>\n",
       "      <td>48.925728</td>\n",
       "      <td>61.532398</td>\n",
       "      <td>117.926628</td>\n",
       "      <td>426.387177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>436.929138</td>\n",
       "      <td>257.286652</td>\n",
       "      <td>142.416565</td>\n",
       "      <td>103.530914</td>\n",
       "      <td>237.286880</td>\n",
       "      <td>165.742447</td>\n",
       "      <td>139.002731</td>\n",
       "      <td>96.665916</td>\n",
       "      <td>61.467873</td>\n",
       "      <td>148.375351</td>\n",
       "      <td>...</td>\n",
       "      <td>60.922173</td>\n",
       "      <td>94.733894</td>\n",
       "      <td>120.193581</td>\n",
       "      <td>464.926147</td>\n",
       "      <td>128.524399</td>\n",
       "      <td>49.837914</td>\n",
       "      <td>49.139256</td>\n",
       "      <td>61.716370</td>\n",
       "      <td>118.741272</td>\n",
       "      <td>426.840820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>435.715790</td>\n",
       "      <td>258.103729</td>\n",
       "      <td>142.152908</td>\n",
       "      <td>103.618484</td>\n",
       "      <td>238.099686</td>\n",
       "      <td>166.939377</td>\n",
       "      <td>139.138031</td>\n",
       "      <td>97.074165</td>\n",
       "      <td>61.203766</td>\n",
       "      <td>148.016083</td>\n",
       "      <td>...</td>\n",
       "      <td>61.838516</td>\n",
       "      <td>94.519279</td>\n",
       "      <td>120.288773</td>\n",
       "      <td>466.051239</td>\n",
       "      <td>129.448135</td>\n",
       "      <td>49.980442</td>\n",
       "      <td>49.119843</td>\n",
       "      <td>61.735729</td>\n",
       "      <td>118.986649</td>\n",
       "      <td>427.826935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>428.177216</td>\n",
       "      <td>254.685867</td>\n",
       "      <td>141.635391</td>\n",
       "      <td>103.608757</td>\n",
       "      <td>236.170517</td>\n",
       "      <td>166.321289</td>\n",
       "      <td>139.157349</td>\n",
       "      <td>96.908920</td>\n",
       "      <td>61.086388</td>\n",
       "      <td>148.453018</td>\n",
       "      <td>...</td>\n",
       "      <td>61.424686</td>\n",
       "      <td>94.548538</td>\n",
       "      <td>120.050789</td>\n",
       "      <td>465.182739</td>\n",
       "      <td>128.154922</td>\n",
       "      <td>49.771404</td>\n",
       "      <td>49.090725</td>\n",
       "      <td>61.919701</td>\n",
       "      <td>118.152359</td>\n",
       "      <td>424.099304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>422.508331</td>\n",
       "      <td>251.307861</td>\n",
       "      <td>139.965637</td>\n",
       "      <td>102.908180</td>\n",
       "      <td>234.358871</td>\n",
       "      <td>163.927460</td>\n",
       "      <td>138.258636</td>\n",
       "      <td>95.616158</td>\n",
       "      <td>60.675556</td>\n",
       "      <td>147.316986</td>\n",
       "      <td>...</td>\n",
       "      <td>60.330986</td>\n",
       "      <td>94.714371</td>\n",
       "      <td>119.298744</td>\n",
       "      <td>460.415894</td>\n",
       "      <td>127.007538</td>\n",
       "      <td>49.486343</td>\n",
       "      <td>48.595737</td>\n",
       "      <td>61.358109</td>\n",
       "      <td>116.886238</td>\n",
       "      <td>418.754486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5032 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MSFT        AAPL         JNJ         XOM         JPM  \\\n",
       "Date                                                                     \n",
       "2005-01-03   18.454880    0.949987   34.751911   25.093662   22.368937   \n",
       "2005-01-04   18.523895    0.959743   34.641403   24.923332   22.138399   \n",
       "2005-01-05   18.482491    0.968149   34.619312   24.793068   22.184502   \n",
       "2005-01-06   18.461790    0.968900   34.718746   25.108692   22.311295   \n",
       "2005-01-07   18.406567    1.039446   34.591671   24.943365   22.132635   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-12-23  432.871429  254.367020  141.850220  103.433617  233.448151   \n",
       "2024-12-24  436.929138  257.286652  142.416565  103.530914  237.286880   \n",
       "2024-12-26  435.715790  258.103729  142.152908  103.618484  238.099686   \n",
       "2024-12-27  428.177216  254.685867  141.635391  103.608757  236.170517   \n",
       "2024-12-30  422.508331  251.307861  139.965637  102.908180  234.358871   \n",
       "\n",
       "                    PG         CVX        MRK         KO         PEP  ...  \\\n",
       "Date                                                                  ...   \n",
       "2005-01-03   31.104504   23.147207  14.135262  11.093916   28.976854  ...   \n",
       "2005-01-04   30.715654   22.988049  14.076481  10.939011   28.770435  ...   \n",
       "2005-01-05   31.036873   23.138121  14.171439  10.888270   28.803917  ...   \n",
       "2005-01-06   31.189054   23.524668  14.270920  10.979074   29.010326  ...   \n",
       "2005-01-07   31.515942   23.260893  14.076481  10.992427   29.261377  ...   \n",
       "...                ...         ...        ...        ...         ...  ...   \n",
       "2024-12-23  164.928162  138.162003  96.588165  61.017918  146.899445  ...   \n",
       "2024-12-24  165.742447  139.002731  96.665916  61.467873  148.375351  ...   \n",
       "2024-12-26  166.939377  139.138031  97.074165  61.203766  148.016083  ...   \n",
       "2024-12-27  166.321289  139.157349  96.908920  61.086388  148.453018  ...   \n",
       "2024-12-30  163.927460  138.258636  95.616158  60.675556  147.316986  ...   \n",
       "\n",
       "                   KR        COP         UPS         NOC         KMB  \\\n",
       "Date                                                                   \n",
       "2005-01-03   6.069591  16.229395   44.609112   31.197931   30.214354   \n",
       "2005-01-04   5.906789  16.123270   44.042339   30.529194   30.228394   \n",
       "2005-01-05   5.857239  16.242908   43.953110   30.994419   29.708813   \n",
       "2005-01-06   5.811234  16.478315   43.905884   30.913008   30.190958   \n",
       "2005-01-07   5.885553  16.374115   43.821911   30.849022   30.022442   \n",
       "...               ...        ...         ...         ...         ...   \n",
       "2024-12-23  60.064949  94.021751  119.708084  461.087036  127.804871   \n",
       "2024-12-24  60.922173  94.733894  120.193581  464.926147  128.524399   \n",
       "2024-12-26  61.838516  94.519279  120.288773  466.051239  129.448135   \n",
       "2024-12-27  61.424686  94.548538  120.050789  465.182739  128.154922   \n",
       "2024-12-30  60.330986  94.714371  119.298744  460.415894  127.007538   \n",
       "\n",
       "                   MO        ADM        GIS         PPG          DE  \n",
       "Date                                                                 \n",
       "2005-01-03   4.115128  13.337941  12.691508   21.149090   24.427019  \n",
       "2005-01-04   4.143637  13.192176  12.652571   20.671089   23.844303  \n",
       "2005-01-05   4.136169  12.967444  12.912111   20.378616   23.613228  \n",
       "2005-01-06   4.106984  13.234690  13.006134   20.667944   23.941425  \n",
       "2005-01-07   4.167390  13.265059  13.303864   20.768570   23.609882  \n",
       "...               ...        ...        ...         ...         ...  \n",
       "2024-12-23  49.940445  48.925728  61.532398  117.926628  426.387177  \n",
       "2024-12-24  49.837914  49.139256  61.716370  118.741272  426.840820  \n",
       "2024-12-26  49.980442  49.119843  61.735729  118.986649  427.826935  \n",
       "2024-12-27  49.771404  49.090725  61.919701  118.152359  424.099304  \n",
       "2024-12-30  49.486343  48.595737  61.358109  116.886238  418.754486  \n",
       "\n",
       "[5032 rows x 50 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/snp50.csv', index_col='Date')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dcc50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14c3ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: (5031, 50) (2005-01-04 00:00:00 ~ 2024-12-30 00:00:00)\n",
      "Preprocessed (fit up to 2015-12-31): (5031, 50)\n",
      "Created sequences - X: (4968, 63, 50), y: (4968, 1, 50)\n",
      "\n",
      "Data split by date:\n",
      "Train: 2705 samples (2005-04-06 00:00:00 ~ 2015-12-31 00:00:00)\n",
      "Val:   1006 samples (2016-01-04 00:00:00 ~ 2019-12-31 00:00:00)\n",
      "Test:  1257 samples (2020-01-02 00:00:00 ~ 2024-12-30 00:00:00)\n",
      "\n",
      "DataLoaders created successfully!\n",
      "Batch size: 32\n",
      "Train batches: 85\n",
      "Val batches: 32\n",
      "Test batches: 40\n"
     ]
    }
   ],
   "source": [
    "data_loader = TimeSeriesDataLoader()\n",
    "train_loader, val_loader, test_loader, dates, scaler = data_loader.create_dataloaders(\n",
    "    frequency='daily',\n",
    "    lookback=63,\n",
    "    forecast_horizon=1,\n",
    "    train_end_date='2015-12-31',\n",
    "    val_end_date='2019-12-31',\n",
    "    test_end_date='2024-12-31',\n",
    "    batch_size=32,\n",
    "    use_scaler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "230f6ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([32, 63, 50])\n",
      "Target batch shape: torch.Size([32, 1, 50])\n",
      "Input batch sample: tensor([[-0.1224,  1.1336, -0.1821,  ..., -0.5703,  0.1525, -0.1346],\n",
      "        [-0.1413, -1.0760,  0.4554,  ..., -0.0120,  0.4268,  0.3426],\n",
      "        [-0.2165, -2.8941,  1.2057,  ..., -0.1936, -1.5884,  0.0982],\n",
      "        ...,\n",
      "        [ 0.8632, -0.2616,  0.0137,  ..., -0.3474,  0.6183, -0.2795],\n",
      "        [ 0.1141, -1.0307,  0.6513,  ..., -0.0770, -0.3288,  0.3857],\n",
      "        [ 0.2156,  0.5385,  1.0264,  ...,  0.1467,  0.8667,  0.3309]])\n",
      "Target batch sample: tensor([[ 0.2146, -0.6039,  2.3619,  0.1620,  0.1344,  0.2148,  0.0391, -0.4013,\n",
      "          2.2251,  1.7467, -0.1260,  0.7406,  0.6936, -0.0598,  1.4721,  0.4192,\n",
      "          0.1553,  1.3002,  0.0817,  0.2880,  0.5306,  0.5615,  0.0521,  0.4128,\n",
      "         -0.2519,  0.1275, -0.4455, -0.4414,  0.1521,  0.5335, -0.0804, -0.2480,\n",
      "          0.0295, -0.2706, -0.2784,  0.0506,  0.1203, -0.1763, -0.7946, -0.2175,\n",
      "         -0.1615, -0.1483,  0.5370,  0.5252,  0.7516,  0.1704, -0.2454,  0.8954,\n",
      "         -1.1035,  0.5905]])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    print(\"Input batch shape:\", X_batch.shape)\n",
    "    print(\"Target batch shape:\", y_batch.shape)\n",
    "    \n",
    "    print(\"Input batch sample:\", X_batch[0])\n",
    "    print(\"Target batch sample:\", y_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a579010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train_loader.dataset.X, train_loader.dataset.y\n",
    "X_valid, Y_valid = val_loader.dataset.X, val_loader.dataset.y\n",
    "X_predict, Y_predict = test_loader.dataset.X, test_loader.dataset.y\n",
    "\n",
    "conformal_predictor = SPCI_and_EnbPI(\n",
    "    X_train, X_valid, X_predict,\n",
    "    Y_train, Y_valid, Y_predict,\n",
    "    model_cls=LSTMModel, \n",
    "    scaler=scaler,\n",
    "    loader = data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598e455a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1006, 63, 50])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd2025c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1257, 1, 50])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7bda2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Num 0 (LSTMModel), Epoch 1, Train Loss: 1.1139, Valid Loss: 0.6939\n",
      "Model Num 0 (LSTMModel), Epoch 2, Train Loss: 1.0249, Valid Loss: 0.6930\n",
      "Model Num 0 (LSTMModel), Epoch 3, Train Loss: 1.0154, Valid Loss: 0.6923\n",
      "Model Num 0 (LSTMModel), Epoch 4, Train Loss: 0.9963, Valid Loss: 0.6929\n",
      "Model Num 0 (LSTMModel), Epoch 5, Train Loss: 1.0006, Valid Loss: 0.6925\n",
      "Model Num 0 (LSTMModel), Epoch 6, Train Loss: 1.0037, Valid Loss: 0.6923\n",
      "Model Num 0 (LSTMModel), Epoch 7, Train Loss: 1.0083, Valid Loss: 0.6928\n",
      "Model Num 0 (LSTMModel), Epoch 8, Train Loss: 0.9872, Valid Loss: 0.6935\n",
      "Model Num 0 (LSTMModel), Epoch 9, Train Loss: 0.9858, Valid Loss: 0.6954\n",
      "Model Num 0 (LSTMModel), Epoch 10, Train Loss: 1.0112, Valid Loss: 0.6997\n",
      "Model Num 0 (LSTMModel), Epoch 11, Train Loss: 0.9998, Valid Loss: 0.7009\n",
      "Model Num 0 (LSTMModel), Epoch 12, Train Loss: 0.9693, Valid Loss: 0.6986\n",
      "Model Num 0 (LSTMModel), Epoch 13, Train Loss: 0.9777, Valid Loss: 0.6999\n",
      "Early stopping for model 0 (LSTMModel) at epoch 13!\n",
      "Loading best model for LSTMModel_0 with validation loss: 0.6923\n",
      "------------------------------------------------------------\n",
      "Model Num 1 (LSTMModel), Epoch 1, Train Loss: 1.1488, Valid Loss: 0.6964\n",
      "Model Num 1 (LSTMModel), Epoch 2, Train Loss: 1.0511, Valid Loss: 0.6928\n",
      "Model Num 1 (LSTMModel), Epoch 3, Train Loss: 1.0298, Valid Loss: 0.6925\n",
      "Model Num 1 (LSTMModel), Epoch 4, Train Loss: 1.0301, Valid Loss: 0.6923\n",
      "Model Num 1 (LSTMModel), Epoch 5, Train Loss: 1.0453, Valid Loss: 0.6921\n",
      "Model Num 1 (LSTMModel), Epoch 6, Train Loss: 1.0257, Valid Loss: 0.6924\n",
      "Model Num 1 (LSTMModel), Epoch 7, Train Loss: 1.0211, Valid Loss: 0.6934\n",
      "Model Num 1 (LSTMModel), Epoch 8, Train Loss: 1.0148, Valid Loss: 0.6936\n",
      "Model Num 1 (LSTMModel), Epoch 9, Train Loss: 1.0184, Valid Loss: 0.6985\n",
      "Model Num 1 (LSTMModel), Epoch 10, Train Loss: 1.0184, Valid Loss: 0.6947\n",
      "Model Num 1 (LSTMModel), Epoch 11, Train Loss: 1.0039, Valid Loss: 0.7000\n",
      "Model Num 1 (LSTMModel), Epoch 12, Train Loss: 1.0001, Valid Loss: 0.6940\n",
      "Model Num 1 (LSTMModel), Epoch 13, Train Loss: 0.9846, Valid Loss: 0.7022\n",
      "Model Num 1 (LSTMModel), Epoch 14, Train Loss: 0.9842, Valid Loss: 0.7057\n",
      "Model Num 1 (LSTMModel), Epoch 15, Train Loss: 0.9771, Valid Loss: 0.7013\n",
      "Early stopping for model 1 (LSTMModel) at epoch 15!\n",
      "Loading best model for LSTMModel_1 with validation loss: 0.6921\n",
      "------------------------------------------------------------\n",
      "Model Num 2 (LSTMModel), Epoch 1, Train Loss: 1.1604, Valid Loss: 0.6947\n",
      "Model Num 2 (LSTMModel), Epoch 2, Train Loss: 1.0494, Valid Loss: 0.6938\n",
      "Model Num 2 (LSTMModel), Epoch 3, Train Loss: 1.0446, Valid Loss: 0.6927\n",
      "Model Num 2 (LSTMModel), Epoch 4, Train Loss: 1.0535, Valid Loss: 0.6935\n",
      "Model Num 2 (LSTMModel), Epoch 5, Train Loss: 1.0259, Valid Loss: 0.6936\n",
      "Model Num 2 (LSTMModel), Epoch 6, Train Loss: 1.0263, Valid Loss: 0.6948\n",
      "Model Num 2 (LSTMModel), Epoch 7, Train Loss: 1.0178, Valid Loss: 0.6949\n",
      "Model Num 2 (LSTMModel), Epoch 8, Train Loss: 1.0114, Valid Loss: 0.6942\n",
      "Model Num 2 (LSTMModel), Epoch 9, Train Loss: 1.0076, Valid Loss: 0.6972\n",
      "Model Num 2 (LSTMModel), Epoch 10, Train Loss: 0.9977, Valid Loss: 0.6984\n",
      "Model Num 2 (LSTMModel), Epoch 11, Train Loss: 0.9929, Valid Loss: 0.6972\n",
      "Model Num 2 (LSTMModel), Epoch 12, Train Loss: 0.9907, Valid Loss: 0.7016\n",
      "Model Num 2 (LSTMModel), Epoch 13, Train Loss: 0.9849, Valid Loss: 0.7077\n",
      "Early stopping for model 2 (LSTMModel) at epoch 13!\n",
      "Loading best model for LSTMModel_2 with validation loss: 0.6927\n",
      "------------------------------------------------------------\n",
      "Model Num 3 (LSTMModel), Epoch 1, Train Loss: 1.1161, Valid Loss: 0.6945\n",
      "Model Num 3 (LSTMModel), Epoch 2, Train Loss: 1.0101, Valid Loss: 0.6926\n",
      "Model Num 3 (LSTMModel), Epoch 3, Train Loss: 0.9895, Valid Loss: 0.6932\n",
      "Model Num 3 (LSTMModel), Epoch 4, Train Loss: 0.9927, Valid Loss: 0.6921\n",
      "Model Num 3 (LSTMModel), Epoch 5, Train Loss: 0.9809, Valid Loss: 0.6921\n",
      "Model Num 3 (LSTMModel), Epoch 6, Train Loss: 1.0018, Valid Loss: 0.6920\n",
      "Model Num 3 (LSTMModel), Epoch 7, Train Loss: 1.0014, Valid Loss: 0.6930\n",
      "Model Num 3 (LSTMModel), Epoch 8, Train Loss: 0.9823, Valid Loss: 0.6929\n",
      "Model Num 3 (LSTMModel), Epoch 9, Train Loss: 0.9629, Valid Loss: 0.6942\n",
      "Model Num 3 (LSTMModel), Epoch 10, Train Loss: 0.9619, Valid Loss: 0.6980\n",
      "Model Num 3 (LSTMModel), Epoch 11, Train Loss: 0.9547, Valid Loss: 0.6986\n",
      "Model Num 3 (LSTMModel), Epoch 12, Train Loss: 0.9585, Valid Loss: 0.7098\n",
      "Model Num 3 (LSTMModel), Epoch 13, Train Loss: 0.9488, Valid Loss: 0.7058\n",
      "Model Num 3 (LSTMModel), Epoch 14, Train Loss: 0.9352, Valid Loss: 0.7048\n",
      "Model Num 3 (LSTMModel), Epoch 15, Train Loss: 0.9199, Valid Loss: 0.7204\n",
      "Model Num 3 (LSTMModel), Epoch 16, Train Loss: 0.8904, Valid Loss: 0.7169\n",
      "Early stopping for model 3 (LSTMModel) at epoch 16!\n",
      "Loading best model for LSTMModel_3 with validation loss: 0.6920\n",
      "------------------------------------------------------------\n",
      "Model Num 4 (LSTMModel), Epoch 1, Train Loss: 1.1716, Valid Loss: 0.6945\n",
      "Model Num 4 (LSTMModel), Epoch 2, Train Loss: 1.0709, Valid Loss: 0.6929\n",
      "Model Num 4 (LSTMModel), Epoch 3, Train Loss: 1.0578, Valid Loss: 0.6938\n",
      "Model Num 4 (LSTMModel), Epoch 4, Train Loss: 1.0439, Valid Loss: 0.6934\n",
      "Model Num 4 (LSTMModel), Epoch 5, Train Loss: 1.0427, Valid Loss: 0.6935\n",
      "Model Num 4 (LSTMModel), Epoch 6, Train Loss: 1.0374, Valid Loss: 0.6926\n",
      "Model Num 4 (LSTMModel), Epoch 7, Train Loss: 1.0379, Valid Loss: 0.6940\n",
      "Model Num 4 (LSTMModel), Epoch 8, Train Loss: 1.0328, Valid Loss: 0.6921\n",
      "Model Num 4 (LSTMModel), Epoch 9, Train Loss: 1.0285, Valid Loss: 0.6935\n",
      "Model Num 4 (LSTMModel), Epoch 10, Train Loss: 1.0262, Valid Loss: 0.6937\n",
      "Model Num 4 (LSTMModel), Epoch 11, Train Loss: 1.0305, Valid Loss: 0.6926\n",
      "Model Num 4 (LSTMModel), Epoch 12, Train Loss: 1.0146, Valid Loss: 0.7018\n",
      "Model Num 4 (LSTMModel), Epoch 13, Train Loss: 1.0165, Valid Loss: 0.6918\n",
      "Model Num 4 (LSTMModel), Epoch 14, Train Loss: 1.0147, Valid Loss: 0.6966\n",
      "Model Num 4 (LSTMModel), Epoch 15, Train Loss: 1.0099, Valid Loss: 0.6980\n",
      "Model Num 4 (LSTMModel), Epoch 16, Train Loss: 1.0108, Valid Loss: 0.6932\n",
      "Model Num 4 (LSTMModel), Epoch 17, Train Loss: 1.0014, Valid Loss: 0.6963\n",
      "Model Num 4 (LSTMModel), Epoch 18, Train Loss: 0.9905, Valid Loss: 0.6978\n",
      "Model Num 4 (LSTMModel), Epoch 19, Train Loss: 0.9700, Valid Loss: 0.7036\n",
      "Model Num 4 (LSTMModel), Epoch 20, Train Loss: 0.9157, Valid Loss: 0.6985\n",
      "Model Num 4 (LSTMModel), Epoch 21, Train Loss: 0.8860, Valid Loss: 0.7090\n",
      "Model Num 4 (LSTMModel), Epoch 22, Train Loss: 0.8400, Valid Loss: 0.7125\n",
      "Model Num 4 (LSTMModel), Epoch 23, Train Loss: 0.8079, Valid Loss: 0.7241\n",
      "Early stopping for model 4 (LSTMModel) at epoch 23!\n",
      "Loading best model for LSTMModel_4 with validation loss: 0.6918\n",
      "------------------------------------------------------------\n",
      "Model Num 5 (LSTMModel), Epoch 1, Train Loss: 1.0965, Valid Loss: 0.6938\n",
      "Model Num 5 (LSTMModel), Epoch 2, Train Loss: 1.0178, Valid Loss: 0.6922\n",
      "Model Num 5 (LSTMModel), Epoch 3, Train Loss: 0.9909, Valid Loss: 0.6925\n",
      "Model Num 5 (LSTMModel), Epoch 4, Train Loss: 1.0048, Valid Loss: 0.6923\n",
      "Model Num 5 (LSTMModel), Epoch 5, Train Loss: 0.9826, Valid Loss: 0.6923\n",
      "Model Num 5 (LSTMModel), Epoch 6, Train Loss: 0.9842, Valid Loss: 0.6923\n",
      "Model Num 5 (LSTMModel), Epoch 7, Train Loss: 0.9760, Valid Loss: 0.6927\n",
      "Model Num 5 (LSTMModel), Epoch 8, Train Loss: 0.9816, Valid Loss: 0.6925\n",
      "Model Num 5 (LSTMModel), Epoch 9, Train Loss: 0.9731, Valid Loss: 0.6936\n",
      "Model Num 5 (LSTMModel), Epoch 10, Train Loss: 0.9837, Valid Loss: 0.6948\n",
      "Model Num 5 (LSTMModel), Epoch 11, Train Loss: 0.9748, Valid Loss: 0.6950\n",
      "Model Num 5 (LSTMModel), Epoch 12, Train Loss: 0.9497, Valid Loss: 0.6936\n",
      "Early stopping for model 5 (LSTMModel) at epoch 12!\n",
      "Loading best model for LSTMModel_5 with validation loss: 0.6922\n",
      "------------------------------------------------------------\n",
      "Model Num 6 (LSTMModel), Epoch 1, Train Loss: 1.1707, Valid Loss: 0.6932\n",
      "Model Num 6 (LSTMModel), Epoch 2, Train Loss: 1.0887, Valid Loss: 0.6933\n",
      "Model Num 6 (LSTMModel), Epoch 3, Train Loss: 1.0637, Valid Loss: 0.6935\n",
      "Model Num 6 (LSTMModel), Epoch 4, Train Loss: 1.0549, Valid Loss: 0.6945\n",
      "Model Num 6 (LSTMModel), Epoch 5, Train Loss: 1.0475, Valid Loss: 0.6957\n",
      "Model Num 6 (LSTMModel), Epoch 6, Train Loss: 1.0595, Valid Loss: 0.6951\n",
      "Model Num 6 (LSTMModel), Epoch 7, Train Loss: 1.0330, Valid Loss: 0.6922\n",
      "Model Num 6 (LSTMModel), Epoch 8, Train Loss: 1.0329, Valid Loss: 0.6954\n",
      "Model Num 6 (LSTMModel), Epoch 9, Train Loss: 1.0126, Valid Loss: 0.7011\n",
      "Model Num 6 (LSTMModel), Epoch 10, Train Loss: 1.0023, Valid Loss: 0.6929\n",
      "Model Num 6 (LSTMModel), Epoch 11, Train Loss: 1.0073, Valid Loss: 0.6953\n",
      "Model Num 6 (LSTMModel), Epoch 12, Train Loss: 1.0215, Valid Loss: 0.7109\n",
      "Model Num 6 (LSTMModel), Epoch 13, Train Loss: 0.9835, Valid Loss: 0.7305\n",
      "Model Num 6 (LSTMModel), Epoch 14, Train Loss: 0.9698, Valid Loss: 0.6995\n",
      "Model Num 6 (LSTMModel), Epoch 15, Train Loss: 0.9460, Valid Loss: 0.7152\n",
      "Model Num 6 (LSTMModel), Epoch 16, Train Loss: 0.9351, Valid Loss: 0.7327\n",
      "Model Num 6 (LSTMModel), Epoch 17, Train Loss: 0.8809, Valid Loss: 0.7209\n",
      "Early stopping for model 6 (LSTMModel) at epoch 17!\n",
      "Loading best model for LSTMModel_6 with validation loss: 0.6922\n",
      "------------------------------------------------------------\n",
      "Model Num 7 (LSTMModel), Epoch 1, Train Loss: 1.1518, Valid Loss: 0.6940\n",
      "Model Num 7 (LSTMModel), Epoch 2, Train Loss: 1.0329, Valid Loss: 0.6927\n",
      "Model Num 7 (LSTMModel), Epoch 3, Train Loss: 1.0296, Valid Loss: 0.6931\n",
      "Model Num 7 (LSTMModel), Epoch 4, Train Loss: 1.0163, Valid Loss: 0.6924\n",
      "Model Num 7 (LSTMModel), Epoch 5, Train Loss: 1.0262, Valid Loss: 0.6925\n",
      "Model Num 7 (LSTMModel), Epoch 6, Train Loss: 1.0230, Valid Loss: 0.6923\n",
      "Model Num 7 (LSTMModel), Epoch 7, Train Loss: 1.0100, Valid Loss: 0.6927\n",
      "Model Num 7 (LSTMModel), Epoch 8, Train Loss: 1.0116, Valid Loss: 0.6927\n",
      "Model Num 7 (LSTMModel), Epoch 9, Train Loss: 1.0055, Valid Loss: 0.6926\n",
      "Model Num 7 (LSTMModel), Epoch 10, Train Loss: 1.0023, Valid Loss: 0.6924\n",
      "Model Num 7 (LSTMModel), Epoch 11, Train Loss: 1.0073, Valid Loss: 0.6940\n",
      "Model Num 7 (LSTMModel), Epoch 12, Train Loss: 0.9888, Valid Loss: 0.6991\n",
      "Model Num 7 (LSTMModel), Epoch 13, Train Loss: 1.0086, Valid Loss: 0.7029\n",
      "Model Num 7 (LSTMModel), Epoch 14, Train Loss: 0.9651, Valid Loss: 0.7070\n",
      "Model Num 7 (LSTMModel), Epoch 15, Train Loss: 0.9498, Valid Loss: 0.7219\n",
      "Model Num 7 (LSTMModel), Epoch 16, Train Loss: 0.9139, Valid Loss: 0.7364\n",
      "Early stopping for model 7 (LSTMModel) at epoch 16!\n",
      "Loading best model for LSTMModel_7 with validation loss: 0.6923\n",
      "------------------------------------------------------------\n",
      "Model Num 8 (LSTMModel), Epoch 1, Train Loss: 1.1750, Valid Loss: 0.6942\n",
      "Model Num 8 (LSTMModel), Epoch 2, Train Loss: 1.0777, Valid Loss: 0.6926\n",
      "Model Num 8 (LSTMModel), Epoch 3, Train Loss: 1.0654, Valid Loss: 0.6923\n",
      "Model Num 8 (LSTMModel), Epoch 4, Train Loss: 1.0767, Valid Loss: 0.6923\n",
      "Model Num 8 (LSTMModel), Epoch 5, Train Loss: 1.0612, Valid Loss: 0.6927\n",
      "Model Num 8 (LSTMModel), Epoch 6, Train Loss: 1.0548, Valid Loss: 0.6935\n",
      "Model Num 8 (LSTMModel), Epoch 7, Train Loss: 1.0531, Valid Loss: 0.6946\n",
      "Model Num 8 (LSTMModel), Epoch 8, Train Loss: 1.0542, Valid Loss: 0.6920\n",
      "Model Num 8 (LSTMModel), Epoch 9, Train Loss: 1.0523, Valid Loss: 0.6951\n",
      "Model Num 8 (LSTMModel), Epoch 10, Train Loss: 1.0458, Valid Loss: 0.6970\n",
      "Model Num 8 (LSTMModel), Epoch 11, Train Loss: 1.0739, Valid Loss: 0.6942\n",
      "Model Num 8 (LSTMModel), Epoch 12, Train Loss: 1.0584, Valid Loss: 0.7070\n",
      "Model Num 8 (LSTMModel), Epoch 13, Train Loss: 1.0420, Valid Loss: 0.6938\n",
      "Model Num 8 (LSTMModel), Epoch 14, Train Loss: 1.0376, Valid Loss: 0.7039\n",
      "Model Num 8 (LSTMModel), Epoch 15, Train Loss: 1.0087, Valid Loss: 0.7109\n",
      "Model Num 8 (LSTMModel), Epoch 16, Train Loss: 0.9889, Valid Loss: 0.7248\n",
      "Model Num 8 (LSTMModel), Epoch 17, Train Loss: 0.9546, Valid Loss: 0.7171\n",
      "Model Num 8 (LSTMModel), Epoch 18, Train Loss: 0.9155, Valid Loss: 0.7206\n",
      "Early stopping for model 8 (LSTMModel) at epoch 18!\n",
      "Loading best model for LSTMModel_8 with validation loss: 0.6920\n",
      "------------------------------------------------------------\n",
      "Model Num 9 (LSTMModel), Epoch 1, Train Loss: 1.1739, Valid Loss: 0.6936\n",
      "Model Num 9 (LSTMModel), Epoch 2, Train Loss: 1.0547, Valid Loss: 0.6930\n",
      "Model Num 9 (LSTMModel), Epoch 3, Train Loss: 1.0477, Valid Loss: 0.6923\n",
      "Model Num 9 (LSTMModel), Epoch 4, Train Loss: 1.0411, Valid Loss: 0.6930\n",
      "Model Num 9 (LSTMModel), Epoch 5, Train Loss: 1.0326, Valid Loss: 0.6921\n",
      "Model Num 9 (LSTMModel), Epoch 6, Train Loss: 1.0268, Valid Loss: 0.6920\n",
      "Model Num 9 (LSTMModel), Epoch 7, Train Loss: 1.0333, Valid Loss: 0.6925\n",
      "Model Num 9 (LSTMModel), Epoch 8, Train Loss: 1.0268, Valid Loss: 0.6920\n",
      "Model Num 9 (LSTMModel), Epoch 9, Train Loss: 1.0271, Valid Loss: 0.6925\n",
      "Model Num 9 (LSTMModel), Epoch 10, Train Loss: 1.0284, Valid Loss: 0.6926\n",
      "Model Num 9 (LSTMModel), Epoch 11, Train Loss: 1.0284, Valid Loss: 0.6939\n",
      "Model Num 9 (LSTMModel), Epoch 12, Train Loss: 1.0254, Valid Loss: 0.6929\n",
      "Model Num 9 (LSTMModel), Epoch 13, Train Loss: 1.0232, Valid Loss: 0.6938\n",
      "Model Num 9 (LSTMModel), Epoch 14, Train Loss: 1.0167, Valid Loss: 0.6929\n",
      "Model Num 9 (LSTMModel), Epoch 15, Train Loss: 1.0149, Valid Loss: 0.6982\n",
      "Model Num 9 (LSTMModel), Epoch 16, Train Loss: 1.0015, Valid Loss: 0.6970\n",
      "Model Num 9 (LSTMModel), Epoch 17, Train Loss: 0.9995, Valid Loss: 0.6992\n",
      "Model Num 9 (LSTMModel), Epoch 18, Train Loss: 0.9823, Valid Loss: 0.7149\n",
      "Early stopping for model 9 (LSTMModel) at epoch 18!\n",
      "Loading best model for LSTMModel_9 with validation loss: 0.6920\n",
      "------------------------------------------------------------\n",
      "Model Num 10 (LSTMModel), Epoch 1, Train Loss: 1.2062, Valid Loss: 0.6939\n",
      "Model Num 10 (LSTMModel), Epoch 2, Train Loss: 1.1066, Valid Loss: 0.6943\n",
      "Model Num 10 (LSTMModel), Epoch 3, Train Loss: 1.0991, Valid Loss: 0.6932\n",
      "Model Num 10 (LSTMModel), Epoch 4, Train Loss: 1.0818, Valid Loss: 0.6941\n",
      "Model Num 10 (LSTMModel), Epoch 5, Train Loss: 1.0709, Valid Loss: 0.7014\n",
      "Model Num 10 (LSTMModel), Epoch 6, Train Loss: 1.0943, Valid Loss: 0.6931\n",
      "Model Num 10 (LSTMModel), Epoch 7, Train Loss: 1.0639, Valid Loss: 0.6951\n",
      "Model Num 10 (LSTMModel), Epoch 8, Train Loss: 1.0579, Valid Loss: 0.6988\n",
      "Model Num 10 (LSTMModel), Epoch 9, Train Loss: 1.0527, Valid Loss: 0.6969\n",
      "Model Num 10 (LSTMModel), Epoch 10, Train Loss: 1.0574, Valid Loss: 0.6946\n",
      "Model Num 10 (LSTMModel), Epoch 11, Train Loss: 1.0450, Valid Loss: 0.6976\n",
      "Model Num 10 (LSTMModel), Epoch 12, Train Loss: 1.0387, Valid Loss: 0.6974\n",
      "Model Num 10 (LSTMModel), Epoch 13, Train Loss: 1.0276, Valid Loss: 0.7082\n",
      "Model Num 10 (LSTMModel), Epoch 14, Train Loss: 1.0300, Valid Loss: 0.7014\n",
      "Model Num 10 (LSTMModel), Epoch 15, Train Loss: 1.0210, Valid Loss: 0.7171\n",
      "Model Num 10 (LSTMModel), Epoch 16, Train Loss: 0.9948, Valid Loss: 0.7092\n",
      "Early stopping for model 10 (LSTMModel) at epoch 16!\n",
      "Loading best model for LSTMModel_10 with validation loss: 0.6931\n",
      "------------------------------------------------------------\n",
      "Model Num 11 (LSTMModel), Epoch 1, Train Loss: 1.2011, Valid Loss: 0.6947\n",
      "Model Num 11 (LSTMModel), Epoch 2, Train Loss: 1.1331, Valid Loss: 0.6930\n",
      "Model Num 11 (LSTMModel), Epoch 3, Train Loss: 1.0782, Valid Loss: 0.6930\n",
      "Model Num 11 (LSTMModel), Epoch 4, Train Loss: 1.0768, Valid Loss: 0.6930\n",
      "Model Num 11 (LSTMModel), Epoch 5, Train Loss: 1.0638, Valid Loss: 0.6943\n",
      "Model Num 11 (LSTMModel), Epoch 6, Train Loss: 1.0915, Valid Loss: 0.6933\n",
      "Model Num 11 (LSTMModel), Epoch 7, Train Loss: 1.0542, Valid Loss: 0.6985\n",
      "Model Num 11 (LSTMModel), Epoch 8, Train Loss: 1.0595, Valid Loss: 0.6927\n",
      "Model Num 11 (LSTMModel), Epoch 9, Train Loss: 1.0478, Valid Loss: 0.6964\n",
      "Model Num 11 (LSTMModel), Epoch 10, Train Loss: 1.0447, Valid Loss: 0.6953\n",
      "Model Num 11 (LSTMModel), Epoch 11, Train Loss: 1.0457, Valid Loss: 0.7012\n",
      "Model Num 11 (LSTMModel), Epoch 12, Train Loss: 1.0535, Valid Loss: 0.7199\n",
      "Model Num 11 (LSTMModel), Epoch 13, Train Loss: 1.0152, Valid Loss: 0.7049\n",
      "Model Num 11 (LSTMModel), Epoch 14, Train Loss: 1.0136, Valid Loss: 0.7092\n",
      "Model Num 11 (LSTMModel), Epoch 15, Train Loss: 0.9991, Valid Loss: 0.7146\n",
      "Model Num 11 (LSTMModel), Epoch 16, Train Loss: 0.9868, Valid Loss: 0.7106\n",
      "Model Num 11 (LSTMModel), Epoch 17, Train Loss: 0.9801, Valid Loss: 0.7083\n",
      "Model Num 11 (LSTMModel), Epoch 18, Train Loss: 0.9429, Valid Loss: 0.7808\n",
      "Early stopping for model 11 (LSTMModel) at epoch 18!\n",
      "Loading best model for LSTMModel_11 with validation loss: 0.6927\n",
      "------------------------------------------------------------\n",
      "Model Num 12 (LSTMModel), Epoch 1, Train Loss: 1.2020, Valid Loss: 0.6945\n",
      "Model Num 12 (LSTMModel), Epoch 2, Train Loss: 1.0878, Valid Loss: 0.6931\n",
      "Model Num 12 (LSTMModel), Epoch 3, Train Loss: 1.0824, Valid Loss: 0.6921\n",
      "Model Num 12 (LSTMModel), Epoch 4, Train Loss: 1.0667, Valid Loss: 0.6923\n",
      "Model Num 12 (LSTMModel), Epoch 5, Train Loss: 1.0586, Valid Loss: 0.6923\n",
      "Model Num 12 (LSTMModel), Epoch 6, Train Loss: 1.0573, Valid Loss: 0.6929\n",
      "Model Num 12 (LSTMModel), Epoch 7, Train Loss: 1.0512, Valid Loss: 0.6941\n",
      "Model Num 12 (LSTMModel), Epoch 8, Train Loss: 1.0558, Valid Loss: 0.6937\n",
      "Model Num 12 (LSTMModel), Epoch 9, Train Loss: 1.0584, Valid Loss: 0.6992\n",
      "Model Num 12 (LSTMModel), Epoch 10, Train Loss: 1.0419, Valid Loss: 0.6981\n",
      "Model Num 12 (LSTMModel), Epoch 11, Train Loss: 1.0373, Valid Loss: 0.6982\n",
      "Model Num 12 (LSTMModel), Epoch 12, Train Loss: 1.0443, Valid Loss: 0.7001\n",
      "Model Num 12 (LSTMModel), Epoch 13, Train Loss: 1.0329, Valid Loss: 0.6990\n",
      "Early stopping for model 12 (LSTMModel) at epoch 13!\n",
      "Loading best model for LSTMModel_12 with validation loss: 0.6921\n",
      "------------------------------------------------------------\n",
      "Model Num 13 (LSTMModel), Epoch 1, Train Loss: 1.1550, Valid Loss: 0.6937\n",
      "Model Num 13 (LSTMModel), Epoch 2, Train Loss: 1.0364, Valid Loss: 0.6925\n",
      "Model Num 13 (LSTMModel), Epoch 3, Train Loss: 1.0224, Valid Loss: 0.6923\n",
      "Model Num 13 (LSTMModel), Epoch 4, Train Loss: 1.0186, Valid Loss: 0.6934\n",
      "Model Num 13 (LSTMModel), Epoch 5, Train Loss: 1.0314, Valid Loss: 0.6929\n",
      "Model Num 13 (LSTMModel), Epoch 6, Train Loss: 1.0077, Valid Loss: 0.6930\n",
      "Model Num 13 (LSTMModel), Epoch 7, Train Loss: 1.0076, Valid Loss: 0.6949\n",
      "Model Num 13 (LSTMModel), Epoch 8, Train Loss: 1.0014, Valid Loss: 0.6940\n",
      "Model Num 13 (LSTMModel), Epoch 9, Train Loss: 1.0046, Valid Loss: 0.6961\n",
      "Model Num 13 (LSTMModel), Epoch 10, Train Loss: 0.9935, Valid Loss: 0.7046\n",
      "Model Num 13 (LSTMModel), Epoch 11, Train Loss: 0.9889, Valid Loss: 0.7012\n",
      "Model Num 13 (LSTMModel), Epoch 12, Train Loss: 0.9801, Valid Loss: 0.7000\n",
      "Model Num 13 (LSTMModel), Epoch 13, Train Loss: 0.9861, Valid Loss: 0.7165\n",
      "Early stopping for model 13 (LSTMModel) at epoch 13!\n",
      "Loading best model for LSTMModel_13 with validation loss: 0.6923\n",
      "------------------------------------------------------------\n",
      "Model Num 14 (LSTMModel), Epoch 1, Train Loss: 1.1410, Valid Loss: 0.6941\n",
      "Model Num 14 (LSTMModel), Epoch 2, Train Loss: 1.0354, Valid Loss: 0.6928\n",
      "Model Num 14 (LSTMModel), Epoch 3, Train Loss: 1.0155, Valid Loss: 0.6923\n",
      "Model Num 14 (LSTMModel), Epoch 4, Train Loss: 1.0137, Valid Loss: 0.6929\n",
      "Model Num 14 (LSTMModel), Epoch 5, Train Loss: 1.0135, Valid Loss: 0.6920\n",
      "Model Num 14 (LSTMModel), Epoch 6, Train Loss: 1.0004, Valid Loss: 0.6921\n",
      "Model Num 14 (LSTMModel), Epoch 7, Train Loss: 1.0024, Valid Loss: 0.6930\n",
      "Model Num 14 (LSTMModel), Epoch 8, Train Loss: 0.9964, Valid Loss: 0.6925\n",
      "Model Num 14 (LSTMModel), Epoch 9, Train Loss: 0.9960, Valid Loss: 0.6921\n",
      "Model Num 14 (LSTMModel), Epoch 10, Train Loss: 0.9839, Valid Loss: 0.6931\n",
      "Model Num 14 (LSTMModel), Epoch 11, Train Loss: 0.9758, Valid Loss: 0.6928\n",
      "Model Num 14 (LSTMModel), Epoch 12, Train Loss: 0.9618, Valid Loss: 0.6959\n",
      "Model Num 14 (LSTMModel), Epoch 13, Train Loss: 0.9655, Valid Loss: 0.6969\n",
      "Model Num 14 (LSTMModel), Epoch 14, Train Loss: 0.9510, Valid Loss: 0.7038\n",
      "Model Num 14 (LSTMModel), Epoch 15, Train Loss: 0.9205, Valid Loss: 0.7090\n",
      "Early stopping for model 14 (LSTMModel) at epoch 15!\n",
      "Loading best model for LSTMModel_14 with validation loss: 0.6920\n",
      "------------------------------------------------------------\n",
      "Model Num 15 (LSTMModel), Epoch 1, Train Loss: 1.1691, Valid Loss: 0.6959\n",
      "Model Num 15 (LSTMModel), Epoch 2, Train Loss: 1.0524, Valid Loss: 0.6929\n",
      "Model Num 15 (LSTMModel), Epoch 3, Train Loss: 1.0556, Valid Loss: 0.6930\n",
      "Model Num 15 (LSTMModel), Epoch 4, Train Loss: 1.0346, Valid Loss: 0.6924\n",
      "Model Num 15 (LSTMModel), Epoch 5, Train Loss: 1.0215, Valid Loss: 0.6932\n",
      "Model Num 15 (LSTMModel), Epoch 6, Train Loss: 1.0218, Valid Loss: 0.6926\n",
      "Model Num 15 (LSTMModel), Epoch 7, Train Loss: 1.0297, Valid Loss: 0.6929\n",
      "Model Num 15 (LSTMModel), Epoch 8, Train Loss: 1.0596, Valid Loss: 0.6931\n",
      "Model Num 15 (LSTMModel), Epoch 9, Train Loss: 1.0211, Valid Loss: 0.6932\n",
      "Model Num 15 (LSTMModel), Epoch 10, Train Loss: 1.0113, Valid Loss: 0.6948\n",
      "Model Num 15 (LSTMModel), Epoch 11, Train Loss: 1.0199, Valid Loss: 0.6936\n",
      "Model Num 15 (LSTMModel), Epoch 12, Train Loss: 1.0073, Valid Loss: 0.7092\n",
      "Model Num 15 (LSTMModel), Epoch 13, Train Loss: 1.0181, Valid Loss: 0.7056\n",
      "Model Num 15 (LSTMModel), Epoch 14, Train Loss: 0.9929, Valid Loss: 0.7003\n",
      "Early stopping for model 15 (LSTMModel) at epoch 14!\n",
      "Loading best model for LSTMModel_15 with validation loss: 0.6924\n",
      "------------------------------------------------------------\n",
      "Model Num 16 (LSTMModel), Epoch 1, Train Loss: 1.1658, Valid Loss: 0.6936\n",
      "Model Num 16 (LSTMModel), Epoch 2, Train Loss: 1.0285, Valid Loss: 0.6929\n",
      "Model Num 16 (LSTMModel), Epoch 3, Train Loss: 1.0117, Valid Loss: 0.6926\n",
      "Model Num 16 (LSTMModel), Epoch 4, Train Loss: 1.0138, Valid Loss: 0.6928\n",
      "Model Num 16 (LSTMModel), Epoch 5, Train Loss: 1.0097, Valid Loss: 0.6929\n",
      "Model Num 16 (LSTMModel), Epoch 6, Train Loss: 1.0047, Valid Loss: 0.6921\n",
      "Model Num 16 (LSTMModel), Epoch 7, Train Loss: 0.9967, Valid Loss: 0.6922\n",
      "Model Num 16 (LSTMModel), Epoch 8, Train Loss: 0.9935, Valid Loss: 0.6932\n",
      "Model Num 16 (LSTMModel), Epoch 9, Train Loss: 0.9999, Valid Loss: 0.6925\n",
      "Model Num 16 (LSTMModel), Epoch 10, Train Loss: 0.9811, Valid Loss: 0.6937\n",
      "Model Num 16 (LSTMModel), Epoch 11, Train Loss: 0.9891, Valid Loss: 0.6920\n",
      "Model Num 16 (LSTMModel), Epoch 12, Train Loss: 0.9682, Valid Loss: 0.6927\n",
      "Model Num 16 (LSTMModel), Epoch 13, Train Loss: 0.9637, Valid Loss: 0.7023\n",
      "Model Num 16 (LSTMModel), Epoch 14, Train Loss: 0.9623, Valid Loss: 0.7161\n",
      "Model Num 16 (LSTMModel), Epoch 15, Train Loss: 0.9712, Valid Loss: 0.6973\n",
      "Model Num 16 (LSTMModel), Epoch 16, Train Loss: 0.9559, Valid Loss: 0.7088\n",
      "Model Num 16 (LSTMModel), Epoch 17, Train Loss: 0.9164, Valid Loss: 0.7302\n",
      "Model Num 16 (LSTMModel), Epoch 18, Train Loss: 0.8649, Valid Loss: 0.7306\n",
      "Model Num 16 (LSTMModel), Epoch 19, Train Loss: 0.8254, Valid Loss: 0.7199\n",
      "Model Num 16 (LSTMModel), Epoch 20, Train Loss: 0.7724, Valid Loss: 0.7378\n",
      "Model Num 16 (LSTMModel), Epoch 21, Train Loss: 0.7489, Valid Loss: 0.7478\n",
      "Early stopping for model 16 (LSTMModel) at epoch 21!\n",
      "Loading best model for LSTMModel_16 with validation loss: 0.6920\n",
      "------------------------------------------------------------\n",
      "Model Num 17 (LSTMModel), Epoch 1, Train Loss: 1.1538, Valid Loss: 0.6939\n",
      "Model Num 17 (LSTMModel), Epoch 2, Train Loss: 1.0780, Valid Loss: 0.6944\n",
      "Model Num 17 (LSTMModel), Epoch 3, Train Loss: 1.0524, Valid Loss: 0.6929\n",
      "Model Num 17 (LSTMModel), Epoch 4, Train Loss: 1.0503, Valid Loss: 0.6935\n",
      "Model Num 17 (LSTMModel), Epoch 5, Train Loss: 1.0521, Valid Loss: 0.6933\n",
      "Model Num 17 (LSTMModel), Epoch 6, Train Loss: 1.0390, Valid Loss: 0.6943\n",
      "Model Num 17 (LSTMModel), Epoch 7, Train Loss: 1.0412, Valid Loss: 0.7020\n",
      "Model Num 17 (LSTMModel), Epoch 8, Train Loss: 1.0357, Valid Loss: 0.6935\n",
      "Model Num 17 (LSTMModel), Epoch 9, Train Loss: 1.0303, Valid Loss: 0.7167\n",
      "Model Num 17 (LSTMModel), Epoch 10, Train Loss: 1.0181, Valid Loss: 0.6957\n",
      "Model Num 17 (LSTMModel), Epoch 11, Train Loss: 1.0174, Valid Loss: 0.6969\n",
      "Model Num 17 (LSTMModel), Epoch 12, Train Loss: 1.0048, Valid Loss: 0.7075\n",
      "Model Num 17 (LSTMModel), Epoch 13, Train Loss: 0.9923, Valid Loss: 0.7183\n",
      "Early stopping for model 17 (LSTMModel) at epoch 13!\n",
      "Loading best model for LSTMModel_17 with validation loss: 0.6929\n",
      "------------------------------------------------------------\n",
      "Model Num 18 (LSTMModel), Epoch 1, Train Loss: 1.1599, Valid Loss: 0.6941\n",
      "Model Num 18 (LSTMModel), Epoch 2, Train Loss: 1.0566, Valid Loss: 0.6930\n",
      "Model Num 18 (LSTMModel), Epoch 3, Train Loss: 1.0518, Valid Loss: 0.6923\n",
      "Model Num 18 (LSTMModel), Epoch 4, Train Loss: 1.0462, Valid Loss: 0.6924\n",
      "Model Num 18 (LSTMModel), Epoch 5, Train Loss: 1.0656, Valid Loss: 0.6921\n",
      "Model Num 18 (LSTMModel), Epoch 6, Train Loss: 1.0313, Valid Loss: 0.6923\n",
      "Model Num 18 (LSTMModel), Epoch 7, Train Loss: 1.0423, Valid Loss: 0.6929\n",
      "Model Num 18 (LSTMModel), Epoch 8, Train Loss: 1.0443, Valid Loss: 0.6928\n",
      "Model Num 18 (LSTMModel), Epoch 9, Train Loss: 1.0357, Valid Loss: 0.6931\n",
      "Model Num 18 (LSTMModel), Epoch 10, Train Loss: 1.0334, Valid Loss: 0.6929\n",
      "Model Num 18 (LSTMModel), Epoch 11, Train Loss: 1.0421, Valid Loss: 0.6930\n",
      "Model Num 18 (LSTMModel), Epoch 12, Train Loss: 1.0446, Valid Loss: 0.6931\n",
      "Model Num 18 (LSTMModel), Epoch 13, Train Loss: 1.0297, Valid Loss: 0.6940\n",
      "Model Num 18 (LSTMModel), Epoch 14, Train Loss: 1.0226, Valid Loss: 0.6931\n",
      "Model Num 18 (LSTMModel), Epoch 15, Train Loss: 1.0233, Valid Loss: 0.6951\n",
      "Early stopping for model 18 (LSTMModel) at epoch 15!\n",
      "Loading best model for LSTMModel_18 with validation loss: 0.6921\n",
      "------------------------------------------------------------\n",
      "Model Num 19 (LSTMModel), Epoch 1, Train Loss: 1.1149, Valid Loss: 0.6943\n",
      "Model Num 19 (LSTMModel), Epoch 2, Train Loss: 1.0183, Valid Loss: 0.6928\n",
      "Model Num 19 (LSTMModel), Epoch 3, Train Loss: 0.9871, Valid Loss: 0.6927\n",
      "Model Num 19 (LSTMModel), Epoch 4, Train Loss: 0.9815, Valid Loss: 0.6939\n",
      "Model Num 19 (LSTMModel), Epoch 5, Train Loss: 0.9835, Valid Loss: 0.6924\n",
      "Model Num 19 (LSTMModel), Epoch 6, Train Loss: 0.9769, Valid Loss: 0.6924\n",
      "Model Num 19 (LSTMModel), Epoch 7, Train Loss: 0.9715, Valid Loss: 0.6929\n",
      "Model Num 19 (LSTMModel), Epoch 8, Train Loss: 0.9680, Valid Loss: 0.6945\n",
      "Model Num 19 (LSTMModel), Epoch 9, Train Loss: 0.9626, Valid Loss: 0.6923\n",
      "Model Num 19 (LSTMModel), Epoch 10, Train Loss: 0.9659, Valid Loss: 0.6968\n",
      "Model Num 19 (LSTMModel), Epoch 11, Train Loss: 0.9550, Valid Loss: 0.6934\n",
      "Model Num 19 (LSTMModel), Epoch 12, Train Loss: 0.9696, Valid Loss: 0.7050\n",
      "Model Num 19 (LSTMModel), Epoch 13, Train Loss: 0.9503, Valid Loss: 0.7088\n",
      "Model Num 19 (LSTMModel), Epoch 14, Train Loss: 0.9346, Valid Loss: 0.7090\n",
      "Model Num 19 (LSTMModel), Epoch 15, Train Loss: 0.9094, Valid Loss: 0.7175\n",
      "Model Num 19 (LSTMModel), Epoch 16, Train Loss: 0.8997, Valid Loss: 0.7579\n",
      "Model Num 19 (LSTMModel), Epoch 17, Train Loss: 0.8718, Valid Loss: 0.7159\n",
      "Model Num 19 (LSTMModel), Epoch 18, Train Loss: 0.8216, Valid Loss: 0.7517\n",
      "Model Num 19 (LSTMModel), Epoch 19, Train Loss: 0.7892, Valid Loss: 0.7335\n",
      "Early stopping for model 19 (LSTMModel) at epoch 19!\n",
      "Loading best model for LSTMModel_19 with validation loss: 0.6923\n",
      "------------------------------------------------------------\n",
      "(1006,)\n",
      "Shape of slided e_t lists is (1257, 1006)\n",
      "Radius of Ellipsoid at test 0 is -1.612500786781311\n",
      "Radius of Ellipsoid at test 62 is 27.9117693901062\n",
      "Radius of Ellipsoid at test 124 is 12.092957019805908\n",
      "Radius of Ellipsoid at test 186 is 11.329946994781494\n",
      "Radius of Ellipsoid at test 248 is 8.69284963607788\n",
      "Radius of Ellipsoid at test 310 is 9.016574144363403\n",
      "Radius of Ellipsoid at test 372 is 8.400694847106934\n",
      "Radius of Ellipsoid at test 434 is 7.831685304641724\n",
      "Radius of Ellipsoid at test 496 is 12.841021060943604\n",
      "Radius of Ellipsoid at test 558 is 9.150264263153076\n",
      "Radius of Ellipsoid at test 620 is 11.738649368286133\n",
      "Radius of Ellipsoid at test 682 is 12.878275394439697\n",
      "Radius of Ellipsoid at test 744 is 8.412648677825928\n",
      "Radius of Ellipsoid at test 806 is 12.646120071411133\n",
      "Radius of Ellipsoid at test 868 is 12.04430341720581\n",
      "Radius of Ellipsoid at test 930 is -3.806815505027771\n",
      "Radius of Ellipsoid at test 992 is 8.053036212921143\n",
      "Radius of Ellipsoid at test 1054 is 9.453678131103516\n",
      "Radius of Ellipsoid at test 1116 is 9.063948631286621\n",
      "Radius of Ellipsoid at test 1178 is -3.5384544134140015\n",
      "Radius of Ellipsoid at test 1240 is 22.995436191558838\n",
      "Finish Computing 1257 unique Prediction Intervals, took 191.83845353126526 secs.\n",
      "Average Coverage is 0.809, Average Ellipsoid Volume is 1.42e-34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8090692124105012), np.float64(1.4185378676762372e-34))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = conformal_predictor.fit_bootstrap_models_online_multistep(B=20, EPOCHS=50) # B is the number of bootstrap models\n",
    "conformal_predictor.compute_Widths_Ensemble_online(alpha=0.05, smallT=False, use_SPCI=True) # alpha is your significance level\n",
    "# conformal_predictor.use_local_ellipsoid = True\n",
    "conformal_predictor.get_results()\n",
    "# 4. Call the new method to get results in the original scale\n",
    "# original_scale_results = conformal_predictor.()\n",
    "\n",
    "# # You can now access the results\n",
    "# if original_scale_results:\n",
    "#     original_predictions = original_scale_results['predictions']\n",
    "#     original_lower_bounds = original_scale_results['lower_bounds']\n",
    "#     original_upper_bounds = original_scale_results['upper_bounds']\n",
    "    \n",
    "#     print(\"\\nSample of inverse-transformed results:\")\n",
    "#     print(\"Predictions:\", original_predictions[0])\n",
    "#     print(\"Lower Bounds:\", original_lower_bounds[0])\n",
    "#     print(\"Upper Bounds:\", original_upper_bounds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b86209fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>XOM</th>\n",
       "      <th>JPM</th>\n",
       "      <th>PG</th>\n",
       "      <th>CVX</th>\n",
       "      <th>MRK</th>\n",
       "      <th>KO</th>\n",
       "      <th>PEP</th>\n",
       "      <th>...</th>\n",
       "      <th>KR</th>\n",
       "      <th>COP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>NOC</th>\n",
       "      <th>KMB</th>\n",
       "      <th>MO</th>\n",
       "      <th>ADM</th>\n",
       "      <th>GIS</th>\n",
       "      <th>PPG</th>\n",
       "      <th>DE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>-0.012257</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.006286</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.013096</td>\n",
       "      <td>-0.012339</td>\n",
       "      <td>-0.006437</td>\n",
       "      <td>-0.013036</td>\n",
       "      <td>-0.011509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016017</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>-0.014445</td>\n",
       "      <td>-0.006886</td>\n",
       "      <td>-0.006441</td>\n",
       "      <td>-0.014087</td>\n",
       "      <td>-0.022901</td>\n",
       "      <td>-0.003468</td>\n",
       "      <td>-0.008703</td>\n",
       "      <td>-0.002491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.004562</td>\n",
       "      <td>-0.025059</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022595</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>0.026026</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.005783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.018165</td>\n",
       "      <td>-0.019570</td>\n",
       "      <td>-0.005055</td>\n",
       "      <td>-0.008321</td>\n",
       "      <td>-0.014436</td>\n",
       "      <td>-0.009667</td>\n",
       "      <td>-0.039505</td>\n",
       "      <td>-0.013735</td>\n",
       "      <td>-0.005405</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000951</td>\n",
       "      <td>-0.043249</td>\n",
       "      <td>-0.014199</td>\n",
       "      <td>-0.009980</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>-0.024283</td>\n",
       "      <td>-0.008217</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>-0.011239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>-0.034783</td>\n",
       "      <td>-0.042205</td>\n",
       "      <td>-0.011654</td>\n",
       "      <td>-0.016006</td>\n",
       "      <td>-0.040439</td>\n",
       "      <td>-0.008734</td>\n",
       "      <td>-0.035436</td>\n",
       "      <td>-0.008775</td>\n",
       "      <td>-0.016541</td>\n",
       "      <td>-0.019200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023305</td>\n",
       "      <td>-0.028445</td>\n",
       "      <td>-0.019276</td>\n",
       "      <td>-0.012390</td>\n",
       "      <td>-0.016742</td>\n",
       "      <td>-0.017408</td>\n",
       "      <td>-0.023755</td>\n",
       "      <td>-0.020963</td>\n",
       "      <td>-0.012647</td>\n",
       "      <td>-0.008855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>-0.010683</td>\n",
       "      <td>-0.020202</td>\n",
       "      <td>-0.022399</td>\n",
       "      <td>-0.015677</td>\n",
       "      <td>-0.010721</td>\n",
       "      <td>-0.016936</td>\n",
       "      <td>-0.002643</td>\n",
       "      <td>-0.003689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006574</td>\n",
       "      <td>-0.017477</td>\n",
       "      <td>-0.013067</td>\n",
       "      <td>-0.010845</td>\n",
       "      <td>-0.012849</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>-0.003766</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>-0.007979</td>\n",
       "      <td>-0.016402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23</th>\n",
       "      <td>-0.003092</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>-0.001585</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.008326</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>-0.002053</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.001064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>-0.002777</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>-0.001851</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>-0.004297</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015041</td>\n",
       "      <td>-0.002265</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>-0.017302</td>\n",
       "      <td>-0.013242</td>\n",
       "      <td>-0.003641</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-0.001702</td>\n",
       "      <td>-0.001918</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006692</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>-0.001978</td>\n",
       "      <td>-0.001864</td>\n",
       "      <td>-0.009990</td>\n",
       "      <td>-0.004182</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>-0.007012</td>\n",
       "      <td>-0.008713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>-0.013240</td>\n",
       "      <td>-0.013263</td>\n",
       "      <td>-0.011789</td>\n",
       "      <td>-0.006762</td>\n",
       "      <td>-0.007671</td>\n",
       "      <td>-0.014393</td>\n",
       "      <td>-0.006458</td>\n",
       "      <td>-0.013340</td>\n",
       "      <td>-0.006725</td>\n",
       "      <td>-0.007652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017806</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>-0.006264</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.008953</td>\n",
       "      <td>-0.005727</td>\n",
       "      <td>-0.010083</td>\n",
       "      <td>-0.009070</td>\n",
       "      <td>-0.010716</td>\n",
       "      <td>-0.012603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2263 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSFT      AAPL       JNJ       XOM       JPM        PG  \\\n",
       "Date                                                                     \n",
       "2016-01-04 -0.012257  0.000855 -0.021807 -0.006286 -0.030035 -0.013096   \n",
       "2016-01-05  0.004562 -0.025059  0.004180  0.008520  0.001729  0.003190   \n",
       "2016-01-06 -0.018165 -0.019570 -0.005055 -0.008321 -0.014436 -0.009667   \n",
       "2016-01-07 -0.034783 -0.042205 -0.011654 -0.016006 -0.040439 -0.008734   \n",
       "2016-01-08  0.003067  0.005288 -0.010683 -0.020202 -0.022399 -0.015677   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2024-12-23 -0.003092  0.003065  0.005538  0.004062  0.003325  0.000298   \n",
       "2024-12-24  0.009374  0.011478  0.003993  0.000941  0.016444  0.004937   \n",
       "2024-12-26 -0.002777  0.003176 -0.001851  0.000846  0.003425  0.007222   \n",
       "2024-12-27 -0.017302 -0.013242 -0.003641 -0.000094 -0.008102 -0.003702   \n",
       "2024-12-30 -0.013240 -0.013263 -0.011789 -0.006762 -0.007671 -0.014393   \n",
       "\n",
       "                 CVX       MRK        KO       PEP  ...        KR       COP  \\\n",
       "Date                                                ...                       \n",
       "2016-01-04 -0.012339 -0.006437 -0.013036 -0.011509  ... -0.016017  0.004069   \n",
       "2016-01-05  0.008554  0.012766  0.003538  0.006885  ...  0.022595  0.011092   \n",
       "2016-01-06 -0.039505 -0.013735 -0.005405  0.000302  ... -0.000951 -0.043249   \n",
       "2016-01-07 -0.035436 -0.008775 -0.016541 -0.019200  ... -0.023305 -0.028445   \n",
       "2016-01-08 -0.010721 -0.016936 -0.002643 -0.003689  ... -0.006574 -0.017477   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2024-12-23  0.000840  0.013463 -0.002718 -0.009817  ... -0.014390  0.013246   \n",
       "2024-12-24  0.006085  0.000805  0.007374  0.010047  ...  0.014272  0.007574   \n",
       "2024-12-26  0.000973  0.004223 -0.004297 -0.002421  ...  0.015041 -0.002265   \n",
       "2024-12-27  0.000139 -0.001702 -0.001918  0.002952  ... -0.006692  0.000310   \n",
       "2024-12-30 -0.006458 -0.013340 -0.006725 -0.007652  ... -0.017806  0.001754   \n",
       "\n",
       "                 UPS       NOC       KMB        MO       ADM       GIS  \\\n",
       "Date                                                                     \n",
       "2016-01-04 -0.014445 -0.006886 -0.006441 -0.014087 -0.022901 -0.003468   \n",
       "2016-01-05  0.009911  0.026026  0.020556  0.020213  0.011161 -0.004525   \n",
       "2016-01-06 -0.014199 -0.009980 -0.000465  0.010589 -0.024283 -0.008217   \n",
       "2016-01-07 -0.019276 -0.012390 -0.016742 -0.017408 -0.023755 -0.020963   \n",
       "2016-01-08 -0.013067 -0.010845 -0.012849  0.001720 -0.003766  0.003266   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2024-12-23  0.000557 -0.004984  0.000914 -0.004829 -0.001585 -0.000943   \n",
       "2024-12-24  0.004056  0.008326  0.005630 -0.002053  0.004364  0.002990   \n",
       "2024-12-26  0.000792  0.002420  0.007187  0.002860 -0.000395  0.000314   \n",
       "2024-12-27 -0.001978 -0.001864 -0.009990 -0.004182 -0.000593  0.002980   \n",
       "2024-12-30 -0.006264 -0.010247 -0.008953 -0.005727 -0.010083 -0.009070   \n",
       "\n",
       "                 PPG        DE  \n",
       "Date                            \n",
       "2016-01-04 -0.008703 -0.002491  \n",
       "2016-01-05  0.003573  0.005783  \n",
       "2016-01-06 -0.018716 -0.011239  \n",
       "2016-01-07 -0.012647 -0.008855  \n",
       "2016-01-08 -0.007979 -0.016402  \n",
       "...              ...       ...  \n",
       "2024-12-23 -0.000499 -0.000254  \n",
       "2024-12-24  0.006908  0.001064  \n",
       "2024-12-26  0.002066  0.002310  \n",
       "2024-12-27 -0.007012 -0.008713  \n",
       "2024-12-30 -0.010716 -0.012603  \n",
       "\n",
       "[2263 rows x 50 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index >'2015-12-31']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uq_ro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
