{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f594e782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from data.data_loader import TimeSeriesDataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from layers.multi_cp import SPCI_and_EnbPI\n",
    "from models.lstm import LSTMModel\n",
    "\n",
    "print(\"Data loader imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b14c3ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: (5032, 50) (2005-01-03 00:00:00 ~ 2024-12-30 00:00:00)\n",
      "Resampled to weekly: (1044, 50)\n",
      "Preprocessed (fit up to 2015-12-31): (1044, 50)\n",
      "Created sequences - X: (1032, 12, 50), y: (1032, 1, 50)\n",
      "\n",
      "Data split by date:\n",
      "Train: 561 samples (2005-04-01 00:00:00 ~ 2015-12-25 00:00:00)\n",
      "Val:   53 samples (2016-01-01 00:00:00 ~ 2016-12-30 00:00:00)\n",
      "Test:  418 samples (2017-01-06 00:00:00 ~ 2025-01-03 00:00:00)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TimeSeriesDataset.__init__() got an unexpected keyword argument 'inverse_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m data_loader = TimeSeriesDataLoader()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_loader, val_loader, test_loader, dates, scaler = \u001b[43mdata_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mweekly\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_end_date\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2015-12-31\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_end_date\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2016-12-31\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_end_date\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2027-12-31\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\God_YJ\\Desktop\\코드\\ccpo_kangmin\\data\\data_loader.py:236\u001b[39m, in \u001b[36mTimeSeriesDataLoader.create_dataloaders\u001b[39m\u001b[34m(self, frequency, lookback, forecast_horizon, train_end_date, val_end_date, test_end_date, batch_size, shuffle_train, use_scaler)\u001b[39m\n\u001b[32m    232\u001b[39m     N,L,D = a.shape   \u001b[38;5;66;03m# (N,L,d)\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scaler.inverse_transform(a.reshape(N*L, D)).reshape(N, L, D)\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m train_dataset = \u001b[43mTimeSeriesDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43minverse_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    237\u001b[39m val_dataset = TimeSeriesDataset(X_val, y_val, inverse_fn=inverse_fn)\n\u001b[32m    238\u001b[39m test_dataset = TimeSeriesDataset(X_test, y_test, inverse_fn=inverse_fn)\n",
      "\u001b[31mTypeError\u001b[39m: TimeSeriesDataset.__init__() got an unexpected keyword argument 'inverse_fn'"
     ]
    }
   ],
   "source": [
    "data_loader = TimeSeriesDataLoader()\n",
    "train_loader, val_loader, test_loader, dates, scaler = data_loader.create_dataloaders(\n",
    "    frequency='weekly',\n",
    "    lookback=12,\n",
    "    forecast_horizon=1,\n",
    "    train_end_date='2015-12-31',\n",
    "    val_end_date='2016-12-31',\n",
    "    test_end_date='2027-12-31',\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train_loader.dataset.X, train_loader.dataset.y\n",
    "X_valid, Y_valid = val_loader.dataset.X, val_loader.dataset.y\n",
    "X_predict, Y_predict = test_loader.dataset.X, test_loader.dataset.y\n",
    "\n",
    "\n",
    "conformal_predictor = SPCI_and_EnbPI(\n",
    "    X_train, X_valid, X_predict,\n",
    "    Y_train, Y_valid, Y_predict,\n",
    "    model_cls=LSTMModel, \n",
    "    scaler=scaler  # <-- Pass the scaler here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e455a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53, 12, 50])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2025c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([418, 1, 50])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bda2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has inverse on train? False\n",
      "has inverse on valid? False\n",
      "has inverse on test? False\n",
      "Model Num 0 (LSTMModel), Epoch 1, Train Loss: 1.0713, Valid Loss: 3.1564\n",
      "Model Num 0 (LSTMModel), Epoch 2, Train Loss: 0.7300, Valid Loss: 2.6306\n",
      "Model Num 0 (LSTMModel), Epoch 3, Train Loss: 0.5594, Valid Loss: 2.1516\n",
      "Model Num 0 (LSTMModel), Epoch 4, Train Loss: 0.4531, Valid Loss: 1.7716\n",
      "Model Num 0 (LSTMModel), Epoch 5, Train Loss: 0.3645, Valid Loss: 1.4605\n",
      "Model Num 0 (LSTMModel), Epoch 6, Train Loss: 0.3065, Valid Loss: 1.1993\n",
      "Model Num 0 (LSTMModel), Epoch 7, Train Loss: 0.2603, Valid Loss: 1.0134\n",
      "Model Num 0 (LSTMModel), Epoch 8, Train Loss: 0.2262, Valid Loss: 0.8748\n",
      "Model Num 0 (LSTMModel), Epoch 9, Train Loss: 0.2070, Valid Loss: 0.7681\n",
      "Model Num 0 (LSTMModel), Epoch 10, Train Loss: 0.1851, Valid Loss: 0.6887\n",
      "Loading best model for LSTMModel_0 with validation loss: 0.6887\n",
      "------------------------------------------------------------\n",
      "Model Num 1 (LSTMModel), Epoch 1, Train Loss: 1.0613, Valid Loss: 3.0818\n",
      "Model Num 1 (LSTMModel), Epoch 2, Train Loss: 0.7081, Valid Loss: 2.3576\n",
      "Model Num 1 (LSTMModel), Epoch 3, Train Loss: 0.5449, Valid Loss: 1.8527\n",
      "Model Num 1 (LSTMModel), Epoch 4, Train Loss: 0.4180, Valid Loss: 1.5083\n",
      "Model Num 1 (LSTMModel), Epoch 5, Train Loss: 0.3393, Valid Loss: 1.2603\n",
      "Model Num 1 (LSTMModel), Epoch 6, Train Loss: 0.2788, Valid Loss: 1.0791\n",
      "Model Num 1 (LSTMModel), Epoch 7, Train Loss: 0.2479, Valid Loss: 0.9340\n",
      "Model Num 1 (LSTMModel), Epoch 8, Train Loss: 0.2165, Valid Loss: 0.8382\n",
      "Model Num 1 (LSTMModel), Epoch 9, Train Loss: 0.1924, Valid Loss: 0.7603\n",
      "Model Num 1 (LSTMModel), Epoch 10, Train Loss: 0.1826, Valid Loss: 0.6989\n",
      "Loading best model for LSTMModel_1 with validation loss: 0.6989\n",
      "------------------------------------------------------------\n",
      "Model Num 2 (LSTMModel), Epoch 1, Train Loss: 1.0884, Valid Loss: 3.2215\n",
      "Model Num 2 (LSTMModel), Epoch 2, Train Loss: 0.7294, Valid Loss: 2.6243\n",
      "Model Num 2 (LSTMModel), Epoch 3, Train Loss: 0.5591, Valid Loss: 2.1028\n",
      "Model Num 2 (LSTMModel), Epoch 4, Train Loss: 0.4427, Valid Loss: 1.6890\n",
      "Model Num 2 (LSTMModel), Epoch 5, Train Loss: 0.3582, Valid Loss: 1.3711\n",
      "Model Num 2 (LSTMModel), Epoch 6, Train Loss: 0.2907, Valid Loss: 1.1182\n",
      "Model Num 2 (LSTMModel), Epoch 7, Train Loss: 0.2594, Valid Loss: 0.9306\n",
      "Model Num 2 (LSTMModel), Epoch 8, Train Loss: 0.2274, Valid Loss: 0.8159\n",
      "Model Num 2 (LSTMModel), Epoch 9, Train Loss: 0.1995, Valid Loss: 0.7241\n",
      "Model Num 2 (LSTMModel), Epoch 10, Train Loss: 0.1789, Valid Loss: 0.6273\n",
      "Loading best model for LSTMModel_2 with validation loss: 0.6273\n",
      "------------------------------------------------------------\n",
      "(53,)\n",
      "Shape of slided e_t lists is (418, 53)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "window shape cannot be larger than input array shape",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m results = conformal_predictor.fit_bootstrap_models_online_multistep(B=\u001b[32m3\u001b[39m, EPOCHS=\u001b[32m10\u001b[39m) \u001b[38;5;66;03m# B is the number of bootstrap models\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mconformal_predictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_Widths_Ensemble_online\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmallT\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_SPCI\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# alpha is your significance level\u001b[39;00m\n\u001b[32m      3\u001b[39m conformal_predictor.get_results()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 4. Call the new method to get results in the original scale\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# original_scale_results = conformal_predictor.()\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#     print(\"Lower Bounds:\", original_lower_bounds[0])\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#     print(\"Upper Bounds:\", original_upper_bounds[0])\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\God_YJ\\Desktop\\코드\\ccpo_kangmin\\layers\\multi_cp.py:219\u001b[39m, in \u001b[36mSPCI_and_EnbPI.compute_Widths_Ensemble_online\u001b[39m\u001b[34m(self, alpha, stride, smallT, past_window, use_SPCI, quantile_regr)\u001b[39m\n\u001b[32m    217\u001b[39m     past_resid = resid_strided[i, :]\n\u001b[32m    218\u001b[39m     n2 = \u001b[38;5;28mself\u001b[39m.past_window\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     resid_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmulti_step_QRF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_resid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# Use the fitted regressor.\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# NOTE, residX is NOT the same as before, as it depends on\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;66;03m# \"past_resid\", which has most entries replaced.\u001b[39;00m\n\u001b[32m    225\u001b[39m rfqr= \u001b[38;5;28mself\u001b[39m.QRF_ls[remainder]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\God_YJ\\Desktop\\코드\\ccpo_kangmin\\layers\\multi_cp.py:297\u001b[39m, in \u001b[36mSPCI_and_EnbPI.multi_step_QRF\u001b[39m\u001b[34m(self, past_resid, i, s, n2)\u001b[39m\n\u001b[32m    295\u001b[39m num = \u001b[38;5;28mlen\u001b[39m(past_resid)\n\u001b[32m    296\u001b[39m resid_pred = past_resid[-n2:].reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m residX = \u001b[43msliding_window_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_resid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m-\u001b[49m\u001b[43ms\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[38;5;28mself\u001b[39m.cov_matrix = \u001b[38;5;28mself\u001b[39m.global_cov \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_local_ellipsoid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cov_matrix_ls[i]\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\God_YJ\\anaconda3\\envs\\uq_ro\\Lib\\site-packages\\numpy\\lib\\_stride_tricks_impl.py:332\u001b[39m, in \u001b[36msliding_window_view\u001b[39m\u001b[34m(x, window_shape, axis, subok, writeable)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ax, dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axis, window_shape):\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x_shape_trimmed[ax] < dim:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    333\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mwindow shape cannot be larger than input array shape\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    334\u001b[39m     x_shape_trimmed[ax] -= dim - \u001b[32m1\u001b[39m\n\u001b[32m    335\u001b[39m out_shape = \u001b[38;5;28mtuple\u001b[39m(x_shape_trimmed) + window_shape\n",
      "\u001b[31mValueError\u001b[39m: window shape cannot be larger than input array shape"
     ]
    }
   ],
   "source": [
    "results = conformal_predictor.fit_bootstrap_models_online_multistep(B=3, EPOCHS=10) # B is the number of bootstrap models\n",
    "conformal_predictor.compute_Widths_Ensemble_online(alpha=0.05, smallT=False, use_SPCI=True) # alpha is your significance level\n",
    "conformal_predictor.get_results()\n",
    "# 4. Call the new method to get results in the original scale\n",
    "# original_scale_results = conformal_predictor.()\n",
    "\n",
    "# # You can now access the results\n",
    "# if original_scale_results:\n",
    "#     original_predictions = original_scale_results['predictions']\n",
    "#     original_lower_bounds = original_scale_results['lower_bounds']\n",
    "#     original_upper_bounds = original_scale_results['upper_bounds']\n",
    "    \n",
    "#     print(\"\\nSample of inverse-transformed results:\")\n",
    "#     print(\"Predictions:\", original_predictions[0])\n",
    "#     print(\"Lower Bounds:\", original_lower_bounds[0])\n",
    "#     print(\"Upper Bounds:\", original_upper_bounds[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uq_ro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
